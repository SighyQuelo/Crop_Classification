{"cells":[{"cell_type":"markdown","source":["# Dataset Processing and Creation\n"],"metadata":{"id":"9NqNp5NIHg2V"}},{"cell_type":"markdown","source":["This file contains all the functions and codes to process and create the dataset as well as two tests for features and image visualisation"],"metadata":{"id":"2eddqI3sHrTf"}},{"cell_type":"markdown","metadata":{"id":"2zmCt9XoSR2E"},"source":["## Import\n"]},{"cell_type":"markdown","source":["Import all the useful libraries used in this notebook."],"metadata":{"id":"m49BxEHa06uI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"c-IdofjGSXAH","executionInfo":{"status":"ok","timestamp":1711299086103,"user_tz":0,"elapsed":1166,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}}},"outputs":[],"source":["from skimage.io import imread, imshow\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_openml\n","import progressbar\n","import time\n","from collections import Counter\n","import random\n","import os\n","import pandas as pd\n","import math"]},{"cell_type":"markdown","source":["This cell is to access the Google Drive files when running on google collab."],"metadata":{"id":"-QNXj5CL07uU"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"aEl3y8esSYLn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711299098261,"user_tz":0,"elapsed":1721,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}},"outputId":"6100edb6-588c-42dc-9394-4e48cd083d72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Projet/code\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Projet/code"]},{"cell_type":"markdown","metadata":{"id":"ze-HQHnIL8CJ"},"source":["## Data selection Functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Bkj-OxHOMEaJ","executionInfo":{"status":"ok","timestamp":1711299101282,"user_tz":0,"elapsed":311,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}}},"outputs":[],"source":["\"\"\" Plot the data occurence in function of the type\n","   args\n","         data (Counter Object) : countains the dataset keys and its occurences\"\"\"\n","def plot_data(data):\n","  plt.bar(data.keys(), data.values());\n","  plt.xlabel('Labels')\n","  plt.ylabel('Occurrence')\n","  plt.title('Occurrence of crops types')\n","  plt.show()\n","\n","\n","\"\"\"compute the size of the crop inside the image\n","    args\n","         img (numpy array): crop image form the dataset\n","\n","    return\n","        c (int): the crop size in pixels\"\"\"\n","def getSize(img):\n","  c=0\n","  for row in img[0]:\n","    for pix in row:\n","      if not math.isnan(pix):\n","        c+=1\n","  return c\n","\n","\n","\"\"\"create and process a dataset from wich the clouds pixels have been removed\n","   args\n","         gj (file): Digimap geo jason file that countains the crops information\n","         cover_perc(int): cloud covering above which the image is not kept\n","         fold_path (str): Path to the parcels image folder\n","  return\n","        data_set (dict): processed dataset\"\"\"\n","def getData_noClouds(gj, cover_perc, fold_path):\n","  # init an empty data set\n","  data_set = {\"image\":[], \"cropcode\":[]}\n","  # Get the image for each crop in geo jason file\n","  idx=0;\n","  bar = progressbar.ProgressBar(maxval=len(gj['features'])).start()\n","  for f in gj['features']:\n","    # get the crop code\n","    cc = f['properties']['crop_code']\n","    # get the crop gid and the image file name\n","    gid = f['properties']['gid']\n","    path = fold_path+gid+'.tif'\n","    # verify if the image exist in the folder\n","    if os.path.exists(path):\n","      # read the image\n","      img = imread(path)\n","      # compute the non-cloud mask by searching all the values above 2^12\n","      mask = (img[:, :, 3]<=2**12)|(img[:, :, 2]<=2**12)|(img[:, :, 1]<=2**12)|(img[:, :, 7]<=2**12)\n","      # if the percentage of non-cloud pixel is superior to the cover_perc,\n","      # replace the pixels that the mask indicates to be a cloud (mask[i][j]=False) by numpy nan\n","      if ((np.count_nonzero(mask)/( getSize(img))*100) > cover_perc):\n","        for i in range(len(mask)):\n","          for j in range(len(mask[0])):\n","            if not mask[i][j]:\n","              img[i,j, [3, 2, 1, 7]]=[np.nan, np.nan, np.nan, np.nan]\n","        # add the processed image and its corresponding crop code in the dataset\n","        data_set['image'].append(img)\n","        data_set['cropcode'].append(cc)\n","    idx +=1;\n","    bar.update(idx)\n","  return data_set\n","\n","\n","\"\"\"Balance the dataset to get for each type between x and x+10% data\n","  args:\n","         data_set(dict): dataset to balance\n","  return:\n","          data(dict): balance dataset\"\"\"\n","def equalize(data_set):\n","  # create a counter object\n","  c = Counter(data_set['cropcode'])\n","  key_value = {}\n","  for i in c.keys():\n","    key_value[i] = c[i]\n","  plot_data(key_value)\n","  # plot the occurences of the dataset\n","  print(key_value.keys())\n","  print(key_value.values())\n","  print()\n","  # ask the user to give a lower limit of its choice\n","  print(\"Choose an interval\")\n","  print(\"lower limit\")\n","  low = int(input())\n","  print(\"upper limit at 10%\")\n","  up = int(low+low*0.1)\n","  print(up)\n","  # update the counter so that occurences below the lower limit choose by the user is passed to 0\n","  # else a random occurence will be used\n","  for k in key_value:\n","    v = key_value[k]\n","    if v<low:\n","      key_value[k]=0\n","    else:\n","      rd = random.randint(low, up)\n","      if v<rd:\n","        key_value[k]=v\n","      else:\n","        key_value[k]=rd\n","  # 'ot' (other crops) is passed to 0\n","  key_value['ot']=0\n","  print(key_value)\n","  plot_data(key_value)\n","  # create the new dataset by keeping the number of data determine in the updated counter\n","  count = key_value\n","  cropcode = []\n","  image = []\n","  idx=0;\n","  bar = progressbar.ProgressBar(maxval=len(data_set['cropcode'])).start()\n","  # for each data in the original dataset if the number have not yet been reached add a data in the dataset\n","  for f in range(len(data_set['cropcode'])):\n","    cc = data_set['cropcode'][f]\n","    img = data_set['image'][f]\n","    if count[cc]!=0:\n","      cropcode.append(cc)\n","      image.append(img)\n","      count[cc] = count[cc] - 1\n","    idx +=1;\n","    bar.update(idx)\n","  data = {'image' : image, 'cropcode' : cropcode}\n","  return data\n","\n"]},{"cell_type":"markdown","source":["## Create Dataset"],"metadata":{"id":"9p6UyxUsHWYX"}},{"cell_type":"markdown","source":["This part show the use of the functions developped above\n","\n","Open the Digimap geo jasonn file:"],"metadata":{"id":"peuePpXL1hQF"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"iPpJ97nhNaQp","executionInfo":{"status":"ok","timestamp":1711299105448,"user_tz":0,"elapsed":1550,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}}},"outputs":[],"source":["with open('DataSet/Digimap_data/Train_labels_epsg_32630.geojson') as f:\n","    gj = json.load(f)"]},{"cell_type":"markdown","source":["Get the dataset whith cloud processing and equalize it:"],"metadata":{"id":"gtXaTPeu1h2h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_irlEYOiNNd9"},"outputs":[],"source":["data = getData_noClouds(gj, 60, 'DataSet/Prepared_Train_Dataset/Shapes/20190724/')\n","dataset = equalize(data)"]},{"cell_type":"markdown","source":["Save the dataset:"],"metadata":{"id":"vQtZN_eB1iZz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"05d80Jo1_tzo"},"outputs":[],"source":["np.save('DataSet/data_03_03_july.npy',dataset)"]},{"cell_type":"markdown","source":["## test stats\n"],"metadata":{"id":"s9Ku_6j0JApH"}},{"cell_type":"code","source":["# Load the dataset\n","dataset = np.load(\"DataSet/data_03_03_july.npy\", allow_pickle=True).item()"],"metadata":{"id":"GUraCGQMJIqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the images and the corresponding crops from the choosed dataset\n","image = dataset['image']\n","cropcode = dataset['cropcode']\n","print(\"ww = Winter wheat\" + '\\n' +\n","      \"sb = Spring barley\" + '\\n' +\n","      \"sw = Spring Wheat\" + '\\n' +\n","      \"wb = Winter barley\" + '\\n' +\n","      \"be = Beet (sugar beet / fodder beet)\" + '\\n' +\n","      \"fb = Field beans\" + '\\n' +\n","      \"ma = Maize\" + '\\n' +\n","      \"or = Oilseed rape\" + '\\n' +\n","      \"po = Potatoes\" + '\\n' +\n","      \"gr = Grass\" + '\\n' +\n","      \"pe = Peas\" + '\\n' +\n","      \"wo = Winter oats\")\n","# init the dictionary that will countains the stats\n","d = { 'ww' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'sb' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'sw' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'wb' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'be' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'fb' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'ma' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'or' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'po' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'gr' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'pe' : np.asarray([0,0,0,0,0,0,0,0,0]),\n","      'wo' : np.asarray([0,0,0,0,0,0,0,0,0])\n","      }\n","# compute the mean of each chosen features for each crop type\n","for i in range(len(cropcode)):\n","  img = image[i]/(2**4)\n","  stats =[getSize(img),   np.nanmean(img[:, :,3]), np.nanmean(img[:, :,2]),\n","          np.nanmean(img[:, :,1]), np.nanmean(img[:, :,7]), np.nanstd(img[:, :,3]),\n","          np.nanstd(img[:, :,2]),  np.nanstd(img[:, :,1]),  np.nanstd(img[:, :,7])]\n","  prev_stats = d[cropcode[i]]\n","  new_stats = (prev_stats*i + stats)/(i+1)\n","  d[cropcode[i]] = np.round(new_stats,2)\n","print()\n","df = pd.DataFrame(data=d, index=[\"size\", \"mean Red\", \"mean Green\", \"mean Blue\", \"mean IR\", \"std Red\", \"std Green\", \"std Blue\", \"std IR\"])\n","display(df)"],"metadata":{"id":"R56keFU0JQKJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Images Visualization"],"metadata":{"id":"f5MYPziNR3B8"}},{"cell_type":"code","source":["# Load the dataset\n","dataset = np.load(\"DataSet/data_03_03_may_reduced.npy\", allow_pickle=True).item()"],"metadata":{"id":"Ru0uraFZRwQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the images and the corresponding crops from the choosed dataset\n","image = dataset['image']\n","cropcode = dataset['cropcode']\n","# plot the images of the dataset that corresponds to the labels\n","codes = ['gr', 'sb', 'sw', 'wb', 'ww', 'or']\n","for i in range(len(cropcode)):\n","  if cropcode[i] in codes:\n","    img = image[i]\n","    img = img/(2**12)\n","    if 1:\n","      mx = np.ma.masked_array(img[:,:,3], np.logical_not(np.isnan(img[:,:,3])))\n","      img[:, :,0]=np.array(mx.mask, dtype=int)\n","      plt.figure()\n","      plt.imshow(img[:, :,[3, 2, 1, 0]])\n","      print(cropcode[i], i)\n","      plt.show()"],"metadata":{"id":"0bHw0CfUR9ki"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNN18SDBCQTgO1FihtVKruv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}