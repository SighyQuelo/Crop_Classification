{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMDbHyGymm/49f/70/4v4S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Models Creation, training and assessment"],"metadata":{"id":"Y42yQSyQUn79"}},{"cell_type":"markdown","source":["This file contains the methods, class and function used to create, tune, train and assess the model"],"metadata":{"id":"eSjBrBzPU0FS"}},{"cell_type":"markdown","source":["## Import"],"metadata":{"id":"f7rPgjMSS64L"}},{"cell_type":"markdown","source":["Import all the useful libraries used in this notebook."],"metadata":{"id":"UgePxoQK12yX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpdFShB4SsPE"},"outputs":[],"source":["from skimage.io import imread, imshow\n","from skimage.color import rgb2gray\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import progressbar\n","import time\n","from collections import Counter\n","import math\n","import itertools\n","import csv"]},{"cell_type":"markdown","source":["This cell is to access the Google Drive files when running on google collab and fix the seed to reproduce the results."],"metadata":{"id":"nIKqRIK913Rb"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Projet/code"],"metadata":{"id":"7sDx9GZdSzBQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711190350076,"user_tz":0,"elapsed":24449,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}},"outputId":"a154d228-8ad8-4598-8b1d-510fbeab88a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Projet/code\n"]}]},{"cell_type":"code","source":["np.random.seed(22)"],"metadata":{"id":"ibhUjTl2RjqV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"7Ld0Q0BQInBj"}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"j8Qi97dATA5S"}},{"cell_type":"code","source":["class Dataset:\n","  \"\"\" A class to save and analyse the dataset\n","      Attributes\n","      ----------\n","          size : int\n","                size of the dataset\n","          images : list of numpy array\n","                list of images of the datset\n","          cropcodes : list of str\n","                list of labels of the dataset\n","          stats : list of numpy array\n","                list of extracted features of each images of the dataset\n","          stats_train : list of numpy array\n","                Extracted features for the training\n","          stats_test : list of numpy array\n","                Extracted features for the testinh\n","          cropcode_train : list of str\n","                labels for the training\n","          cropcode_test : list of str\n","                labels for the testing\n","          class_names : list of str\n","                list of the class in the dataset\n","      Methods\n","      -------\n","          print_info():\n","                plot occurences of the dataset\n","          separate_train_test(s):\n","                separate the dataset between training and testing set\n","          display_train_test():\n","                plot occurences of the training and testing sets\n","  \"\"\"\n","\n","  def __init__(self, data):\n","    \"\"\"\n","        Parameters\n","        ----------\n","        data: dict\n","            dataset used\n","    \"\"\"\n","    self.size = len(data['image'])\n","    self.images = []\n","    self.cropcodes = []\n","    self.stats = []\n","    # for each image extract the features and append it in stats list\n","    for img in self.images:\n","      img = np.round(img/(2**4),0)\n","      stat_rgba = [np.nanmean(img[:, :,3]), np.nanstd(img[:, :,3]),\n","                   np.nanmean(img[:, :,2]), np.nanstd(img[:, :,2]),\n","                   np.nanmean(img[:, :,1]), np.nanstd(img[:, :,1]),\n","                   np.nanmean(img[:, :,7]), np.nanstd(img[:, :,7]),\n","                   getSize(img[:, :, 7])]\n","      self.stats.append(stat_rgba)\n","    self.stats = np.asarray(self.stats)/255\n","    # init empty train and testing set\n","    self.stats_train = []\n","    self.stats_test = []\n","    self.cropcode_train = []\n","    self.cropcode_test = []\n","    # get the class names\n","    copy = self.cropcode\n","    self.class_names= list(set(copy))\n","\n","  def print_info(self):\n","    \"\"\" plot occurences of the dataset \"\"\"\n","    c = Counter(self.cropcode)\n","    print(\"ww = Winter wheat\" + '\\n' +\n","          \"sb = Spring barley\" + '\\n' +\n","          \"sw = Spring Wheat\" + '\\n' +\n","          \"wb = Winter barley\" + '\\n' +\n","          \"be = Beet (sugar beet / fodder beet)\" + '\\n' +\n","          \"fb = Field beans\" + '\\n' +\n","          \"ma = Maize\" + '\\n' +\n","          \"or = Oilseed rape\" + '\\n' +\n","          \"po = Potatoes\" + '\\n' +\n","          \"gr = Grass\" + '\\n' +\n","          \"ot = Other crops\" + '\\n' + # i may reject this data\n","          \"pe = Peas\" + '\\n' +\n","          \"wo = Winter oats\")\n","    key_value = {}\n","    for i in sorted(c.keys()):\n","          key_value[i] = c[i]\n","\n","    plt.bar(key_value.keys(), key_value.values())\n","    plt.xlabel('Labels')\n","    plt.ylabel('Occurrence')\n","    plt.title('Occurrence of crops types')\n","    plt.show()\n","\n","  def separate_train_test(self, s):\n","    \"\"\" separate the dataset between training and testing set\n","        Parameters\n","        ----------\n","        s: float\n","            size of the testing set in percent. s is between 0 and 1\n","    \"\"\"\n","    self.stats_train, self.stats_test, self.cropcode_train, self.cropcode_test = train_test_split(self.stats, self.cropcode, test_size=s)\n","\n","    print('Size of training set : ' + str(len(self.cropcode_train)) + ' / ' + str(len(self.cropcode)))\n","    print('Size of testing set : ' + str(len(self.cropcode_test))+ ' / ' + str(len(self.cropcode)))\n","    self.display_train_test()\n","\n","  def display_train_test(self):\n","    \"\"\"plot occurences of the training and testing sets\"\"\"\n","    test = Counter(self.cropcode_test)\n","    train = Counter(self.cropcode_train)\n","    info = \"Dataset size \" + str(self.size)\n","\n","    key_value_train = {};\n","    key_value_test = {};\n","\n","    for i in sorted(test.keys()):\n","      key_value_test[i] = test[i]\n","    for i in sorted(train.keys()):\n","      key_value_train[i] = train[i]\n","\n","    p1 = plt.bar(key_value_train.keys(), key_value_train.values(), width=0.5);\n","    p2 = plt.bar( key_value_test.keys(), key_value_test.values(), width=0.5, bottom=list(key_value_train.values()) );\n","\n","    plt.legend((p1[0], p2[0]), ('Training set', 'Test set'), loc='lower left')\n","    plt.xlabel('Labels')\n","    plt.ylabel('Occurrence')\n","    plt.title('Occurrence of training and testing sets')\n","    plt.show()"],"metadata":{"id":"e8ieHegZTEx7","executionInfo":{"status":"ok","timestamp":1711300529947,"user_tz":0,"elapsed":7,"user":{"displayName":"Marie Quélo","userId":"01879319296652529310"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def getSize(img):\n","  \"\"\"compute the size of the crop inside the image\n","    Parameters\n","    ----------\n","    img: numpy array\n","         crop image form the dataset\n","\n","    Returns\n","    ---------\n","    c : int\n","        the crop size in pixels\"\"\"\n","  c=0\n","  for row in img:\n","    for pix in row:\n","      if not math.isnan(pix):\n","        c+=1\n","  return c"],"metadata":{"id":"fRDLSQshxcVB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Accuracy measure"],"metadata":{"id":"zgBbxV8tyLk1"}},{"cell_type":"markdown","source":[],"metadata":{"id":"TlAKU-iy19KD"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, cohen_kappa_score, ConfusionMatrixDisplay, precision_recall_fscore_support, f1_score\n","import pandas as pd\n","\n","def accuracy_metrics(cropcode_true, cropcode_predicted, class_names):\n","  \"\"\"compute the accuracy of the predciction.\n","    Parameters\n","    ----------\n","    cropcode_true: list str\n","         true labels\n","    cropcode_predicted: list str\n","         predicted labels\n","    class_names: list str\n","        list of the dataset labels\n","  \"\"\"\n","  # compute and plot the confusion matrix\n","  conf_mx = confusion_matrix(cropcode_true, cropcode_predicted, labels=class_names, normalize='true')\n","  disp = ConfusionMatrixDisplay(conf_mx, display_labels=class_names)\n","  disp.plot(cmap='Blues')\n","  # compute the overall accuracy, kappa coefficient and overall f1-score\n","  accuracy = np.trace(conf_mx) / float(np.sum(conf_mx))\n","  print(\"Overall Accuracy : {:0.4f}  (misclass ={:0.4f})\".format(accuracy, 1-accuracy))\n","  kappa = cohen_kappa_score(cropcode_true, cropcode_predicted)\n","  print(\"Cohen's Coefficient : {:0.4f}\".format(kappa))\n","  overall_f1 = f1_score(cropcode_true, cropcode_predicted, average='weighted')\n","  print(\"Overall f1_score : {:0.4f}\".format(overall_f1))\n","  # compute the precisions, recalls and f1-scores and print the data frame\n","  d = {}\n","  d['precison'], d['recall'], d['f1'], _ = precision_recall_fscore_support(cropcode_true, cropcode_predicted, labels=class_names)\n","  df = pd.DataFrame(data=d, index=class_names)\n","  display(df)"],"metadata":{"id":"o5kTW8PeTHJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"G13EjNU4IuZ4"}},{"cell_type":"markdown","source":["## Dataset preparation"],"metadata":{"id":"rR6jv14_DBaP"}},{"cell_type":"code","source":["# read and create dataset struct\n","data = np.load(\"DataSet/data_12_11.npz\", allow_pickle=True)\n","DS = Dataset(data)"],"metadata":{"id":"8Jf5L0NFDHRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print info\n","DS.print_info()"],"metadata":{"id":"ZfmShRaeDyWx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# separate train test\n","DS.separate_train_test(0.2)"],"metadata":{"id":"r2G32o9_DLfD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SVM"],"metadata":{"id":"guUF_LCfTV-3"}},{"cell_type":"markdown","source":["#### Hyperparameter Tuning"],"metadata":{"id":"GCrP0tKB2Rx4"}},{"cell_type":"markdown","source":["Tune the Regularization parameter :"],"metadata":{"id":"APQwLMgq2wVo"}},{"cell_type":"code","source":["from sklearn import svm\n","C = np.linspace(5, 200, 20)\n","\n","idx = 0;\n","score_training = [0.0 for i in range(len(C))]\n","score_testing  = [0.0 for i in range(len(C))]\n","bar = progressbar.ProgressBar(maxval=len(C)).start()\n","# for each C score the training and testing of the model\n","for c in C:\n","  clf = svm.SVC(kernel='linear', C=c)\n","  clf.fit(DS.stats_train, DS.cropcode_train)\n","  score_training[idx] = round(clf.score(DS.stats_train, DS.cropcode_train),2);\n","  score_testing[idx] = round(clf.score(DS.stats_test, DS.cropcode_test),2);\n","  idx +=1;\n","  bar.update(idx)\n","# plot the accuracy of the training and testing in function of C\n","fig, ax1 = plt.subplots()\n","color = 'tab:blue'\n","ax1.set_xlabel('C')\n","ax1.set_ylabel('Accuracy', color=color)\n","ax1.plot(C, score_training, '-bo', label='Training set')\n","ax1.plot(C, score_testing, '--b*', label='Testing set')\n","ax1.tick_params(axis='y', labelcolor=color)\n","plt.legend(loc='upper left')\n","plt.grid()\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.show()"],"metadata":{"id":"BGHOrxNATcSQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tune gamma for the RBF kernel"],"metadata":{"id":"P4P1p-YpehGm"}},{"cell_type":"code","source":["from sklearn import svm\n","C = 100.0\n","gamma = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n","# init the score lists\n","idx = 0;\n","score_training = [0.0 for i in range(len(gamma))]\n","score_testing  = [0.0 for i in range(len(gamma))]\n","bar = progressbar.ProgressBar(maxval=len(gamma)).start()\n","# for each gamma score the training and testing of the model\n","for g in gamma:\n","  clf = svm.SVC(kernel='rbf', C=C, gamma=g)\n","  clf.fit(DS.stats_train, DS.cropcode_train)\n","  score_training[idx] = round(clf.score(DS.stats_train, DS.cropcode_train),2);\n","  score_testing[idx] = round(clf.score(DS.stats_test, DS.cropcode_test),2);\n","  idx +=1;\n","  bar.update(idx)\n","# plot the accuracy of the training and testing in function of gamma\n","fig, ax1 = plt.subplots()\n","color = 'tab:blue'\n","ax1.set_xlabel('gamma')\n","ax1.set_ylabel('Accuracy', color=color)\n","ax1.plot(gamma, score_training, '-bo', label='Training set')\n","ax1.plot(gamma, score_testing, '--b*', label='Testing set')\n","ax1.tick_params(axis='y', labelcolor=color)\n","plt.legend(loc='upper left')\n","plt.grid()\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.show()"],"metadata":{"id":"TqbGrAe-CKPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tune the degree for the polynomial kernel:"],"metadata":{"id":"YnMC6xJieldJ"}},{"cell_type":"code","source":["from sklearn import svm\n","C = 100.0\n","degree = [1,2,3,4,5]\n","# init the score lists\n","idx = 0;\n","score_training = [0.0 for i in range(len(degree))]\n","score_testing  = [0.0 for i in range(len(degree))]\n","bar = progressbar.ProgressBar(maxval=len(degree)).start()\n","# for each degree score the training and testing of the model\n","for d in degree:\n","  clf = svm.SVC(kernel='poly', C=C, degree=d)\n","  clf.fit(DS.stats_train, DS.cropcode_train)\n","  score_training[idx] = round(clf.score(DS.stats_train, DS.cropcode_train),2);\n","  score_testing[idx] = round(clf.score(DS.stats_test, DS.cropcode_test),2);\n","  idx +=1;\n","  bar.update(idx)\n","# plot the accuracy of the training and testing in function of the degree\n","fig, ax1 = plt.subplots()\n","color = 'tab:blue'\n","ax1.set_xlabel('degree')\n","ax1.set_ylabel('Accuracy', color=color)\n","ax1.plot(degree, score_training, '-bo', label='Training set')\n","ax1.plot(degree, score_testing, '--b*', label='Testing set')\n","ax1.tick_params(axis='y', labelcolor=color)\n","plt.legend(loc='upper left')\n","plt.grid()\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.show()"],"metadata":{"id":"-XZUAwRFMveb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Final Model"],"metadata":{"id":"_B4jbaR92Xcs"}},{"cell_type":"markdown","source":["Train the tuned model and assess the prediction produced by this model"],"metadata":{"id":"F6qKR20j2x-p"}},{"cell_type":"code","source":["from sklearn import svm\n","ker = 'linear' #best kernel\n","clf = svm.SVC(kernel=ker, C= 100)\n","clf.fit(DS.stats_train, DS.cropcode_train)\n","prediction = clf.predict(DS.stats_test)\n","\n","# confusion matrix and accuracy metrics\n","conf_mx, df, accuracy, kappa = accuracy_metrics(DS.cropcode_test, prediction, DS.class_names)"],"metadata":{"id":"1uYioQb2ruSz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RF\n"],"metadata":{"id":"l5G1h-z3TZRb"}},{"cell_type":"markdown","source":["#### Hyperparameter Tuning"],"metadata":{"id":"0-7EhoAY2ecG"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","depths = [2,5,8,10,15,20,25,30]\n","trees = [1, 10, 20, 30, 40, 50]\n","\n","# for each number of trees and depth score the training and testing of the model\n","for s in trees:\n","  idx = 0;\n","  score_training = [0.0 for i in range(len(depths))]\n","  score_testing  = [0.0 for i in range(len(depths))]\n","  time_train  = [0.0 for i in range(len(depths))]\n","  time_test  = [0.0 for i in range(len(depths))]\n","  bar = progressbar.ProgressBar(maxval=len(depths)).start()\n","  for d in depths:\n","    clf = RandomForestClassifier(max_depth=d, random_state=0, n_estimators=s)\n","    t = time.process_time()\n","    clf.fit(DS.stats_train, DS.cropcode_train)\n","    time_train[idx] = time.process_time() - t\n","    score_training[idx] = round(clf.score(DS.stats_train, DS.cropcode_train),2);\n","    time_test[idx] = time.process_time() - t - time_train[idx]\n","    score_testing[idx] = round(clf.score(DS.stats_test, DS.cropcode_test),2);\n","    idx +=1;\n","    bar.update(idx)\n","  # plot the accuracy of the training and testing in function of the depth for the number of tree s\n","  fig, ax1 = plt.subplots()\n","  color = 'tab:blue'\n","  ax1.set_xlabel('Depth (trees ='+str(s)+')')\n","  ax1.set_ylabel('Accuracy', color=color)\n","  ax1.plot(depths, score_training, '-bo', label='Training set')\n","  ax1.plot(depths, score_testing, '--b*', label='Testing set')\n","  ax1.tick_params(axis='y', labelcolor=color)\n","  plt.legend(loc='upper left')\n","  plt.grid()\n","  plt.show()"],"metadata":{"id":"b559gs4kTdQe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Final Model"],"metadata":{"id":"suso7Rgk2kFK"}},{"cell_type":"markdown","source":["Train the tuned model and assess the prediction produced by this model"],"metadata":{"id":"-9Yq9H6v2zqp"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","s = 20 # best number of trees\n","d = 10 # best depth\n","\n","clf = RandomForestClassifier(max_depth=d, random_state=0, n_estimators=s)\n","clf.fit(DS.stats_train, DS.cropcode_train)\n","prediction = clf.predict(DS.stats_test)\n","\n","# confusion matrix and accuracy metrics\n","conf_mx, df, accuracy, kappa = accuracy_metrics( DS.cropcode_test, prediction, DS.class_names)"],"metadata":{"id":"s1KfN1byrz2D"},"execution_count":null,"outputs":[]}]}